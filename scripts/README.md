# ğŸ—ï¸ Architecture d'Import GMBS CRM

## ğŸ“‹ Vue d'ensemble

Cette architecture modulaire et robuste permet d'importer des donnÃ©es depuis Google Sheets vers la base de donnÃ©es Supabase en respectant les principes SOLID et en offrant une sÃ©paration claire des responsabilitÃ©s.

## ğŸ¯ Objectifs

- âœ… **Travail local d'abord** : DÃ©veloppement sans connexion internet
- âœ… **Mapping robuste** : Transformation fiable des donnÃ©es CSV vers SQL
- âœ… **Tests unitaires** : Validation automatique du mapping
- âœ… **SÃ©paration des responsabilitÃ©s** : Chaque module a une responsabilitÃ© claire
- âœ… **RÃ©utilisation de l'API existante** : Utilise `supabase-api-v2.ts`

## ğŸ“ Structure du projet

```
scripts/
â”œâ”€â”€ ğŸ“ data-processing/          # Traitement des donnÃ©es
â”‚   â”œâ”€â”€ data-mapper.js              # Mapping CSV â†’ SQL
â”‚   â””â”€â”€ data-validator.js           # Validation des donnÃ©es
â”œâ”€â”€ ğŸ“ database/                 # Base de donnÃ©es
â”‚   â””â”€â”€ database-manager.js         # Gestionnaire d'insertion
â”œâ”€â”€ ğŸ“ local/                    # DÃ©veloppement local
â”‚   â””â”€â”€ local-workflow.js           # Workflow sans internet
â”œâ”€â”€ ğŸ“ tests/                    # Tests unitaires
â”‚   â””â”€â”€ mapping.test.js             # Tests de mapping
â””â”€â”€ import-main.js               # Script principal
```

## ğŸ”§ Modules

### 1. **DataMapper** (`data-processing/data-mapper.js`)

**ResponsabilitÃ©** : Transformation des donnÃ©es CSV vers le schÃ©ma de base de donnÃ©es

**FonctionnalitÃ©s** :
- Mapping des artisans depuis le CSV
- Mapping des interventions depuis le CSV
- Mapping des coÃ»ts d'intervention
- Mapping des clients
- Extraction et nettoyage des donnÃ©es (tÃ©lÃ©phones, emails, adresses)
- Gestion des rÃ©fÃ©rences vers d'autres tables

**Exemple d'utilisation** :
```javascript
const mapper = new DataMapper();
const artisan = await mapper.mapArtisanFromCSV(csvRow);
const intervention = await mapper.mapInterventionFromCSV(csvRow);
```

### 2. **DataValidator** (`data-processing/data-validator.js`)

**ResponsabilitÃ©** : Validation des donnÃ©es mappÃ©es avant insertion

**FonctionnalitÃ©s** :
- Validation selon le schÃ©ma de base de donnÃ©es
- RÃ¨gles de validation spÃ©cifiques (email, tÃ©lÃ©phone, SIRET, etc.)
- Validation en lot
- GÃ©nÃ©ration de rapports de validation

**Exemple d'utilisation** :
```javascript
const validator = new DataValidator();
const result = validator.validate(mappedData, 'artisan');
if (result.isValid) {
  // ProcÃ©der Ã  l'insertion
}
```

### 3. **DatabaseManager** (`database/database-manager.js`)

**ResponsabilitÃ©** : Insertion des donnÃ©es dans la base de donnÃ©es

**FonctionnalitÃ©s** :
- Insertion par lots optimisÃ©e
- Gestion des erreurs d'insertion
- Support du mode dry-run
- Statistiques d'insertion
- Utilisation de l'API Supabase existante

**Exemple d'utilisation** :
```javascript
const dbManager = new DatabaseManager({ dryRun: true });
const results = await dbManager.insertArtisans(mappedArtisans);
```

### 4. **LocalDevelopmentWorkflow** (`local/local-workflow.js`)

**ResponsabilitÃ©** : Workflow de dÃ©veloppement local sans connexion internet

**FonctionnalitÃ©s** :
- Chargement des donnÃ©es CSV locales
- Traitement complet des donnÃ©es
- Sauvegarde des rÃ©sultats mappÃ©s
- GÃ©nÃ©ration de rapports dÃ©taillÃ©s
- Mode dry-run intÃ©grÃ©

**Exemple d'utilisation** :
```javascript
const workflow = new LocalDevelopmentWorkflow({
  dataPath: './data/samples/sheets',
  dryRun: true,
  verbose: true
});
const results = await workflow.run();
```

## ğŸš€ Utilisation

### 1. **DÃ©veloppement local** (recommandÃ© pour commencer)

```bash
# Mode dÃ©veloppement local avec affichage dÃ©taillÃ©
node scripts/import-main.js --local --verbose

# Mode test sans Ã©criture en base
node scripts/import-main.js --local --dry-run --verbose
```

### 2. **Tests unitaires**

```bash
# Lancer les tests de mapping
npm test scripts/tests/mapping.test.js
```

### 3. **Import sÃ©lectif**

```bash
# Import uniquement des artisans
node scripts/import-main.js --local --artisans-only --verbose

# Import uniquement des interventions
node scripts/import-main.js --local --interventions-only --verbose
```

## ğŸ“Š Mapping des donnÃ©es

### **Artisans** (`GMBS-BASEdeDONNÃ‰E_SST_ARTISANS.csv`)

| Colonne CSV | Champ SQL | Transformation |
|-------------|-----------|----------------|
| `Nom PrÃ©nom` | `prenom`, `nom` | SÃ©paration automatique |
| `Adresse Mail` | `email` | Validation email |
| `NumÃ©ro TÃ©lÃ©phone` | `telephone`, `telephone2` | Nettoyage + sÃ©paration |
| `Raison Social` | `raison_sociale` | Nettoyage |
| `Siret` | `siret` | Validation 14 chiffres |
| `Adresse Postale` | `adresse_siege_social`, `ville_siege_social`, `code_postal_siege_social` | Extraction automatique |
| `STATUT` | `statut_id` | RÃ©fÃ©rence vers `artisan_statuses` |
| `Gestionnaire` | `gestionnaire_id` | RÃ©fÃ©rence vers `users` |
| `MÃ‰TIER` | Relation `artisan_metiers` | RÃ©fÃ©rence vers `metiers` |

### **Interventions** (`GMBS-SUIVI_INTER_GMBS_2025.csv`)

| Colonne CSV | Champ SQL | Transformation |
|-------------|-----------|----------------|
| `ID` | `id_inter` | Nettoyage |
| `Date` | `date` | Parsing date |
| `Agence` | `agence_id` | RÃ©fÃ©rence vers `agencies` |
| `Adresse d'intervention` | `adresse`, `ville`, `code_postal` | Extraction automatique |
| `Statut` | `statut_id` | RÃ©fÃ©rence vers `intervention_statuses` |
| `MÃ©tier` | `metier_id` | RÃ©fÃ©rence vers `metiers` |
| `Gest.` | `assigned_user_id` | RÃ©fÃ©rence vers `users` |
| `COUT SST` | Table `intervention_costs` | SÃ©paration des coÃ»ts |
| `COÃ›T MATERIEL` | Table `intervention_costs` | SÃ©paration des coÃ»ts |
| `COUT INTER` | Table `intervention_costs` | SÃ©paration des coÃ»ts |
| `Locataire` | Table `clients` | Extraction client |

## ğŸ§ª Tests

### **Tests de mapping**

Les tests valident :
- âœ… Extraction correcte des prÃ©noms/noms
- âœ… Nettoyage des tÃ©lÃ©phones et emails
- âœ… Parsing des dates et nombres
- âœ… Mapping complet des artisans et interventions
- âœ… Validation des donnÃ©es mappÃ©es
- âœ… Gestion des cas d'erreur

### **ExÃ©cution des tests**

```bash
# Tests complets
npm test

# Tests spÃ©cifiques
npm test -- --testNamePattern="DataMapper"
npm test -- --testNamePattern="DataValidator"
```

## ğŸ“ˆ Workflow recommandÃ©

### **Phase 1 : DÃ©veloppement local**
1. Lancer le workflow local : `node scripts/import-main.js --local --verbose`
2. Analyser les rÃ©sultats dans `./data/processed/`
3. Corriger les erreurs de mapping si nÃ©cessaire
4. Relancer jusqu'Ã  avoir un taux de succÃ¨s acceptable

### **Phase 2 : Tests**
1. Lancer les tests unitaires : `npm test`
2. VÃ©rifier que tous les tests passent
3. Ajouter des tests pour les cas d'erreur spÃ©cifiques

### **Phase 3 : Import rÃ©el**
1. Tester avec `--dry-run` en mode production
2. VÃ©rifier les statistiques d'insertion
3. Lancer l'import rÃ©el quand tout est prÃªt

## ğŸ”§ Configuration

### **Variables d'environnement**

```env
# Base de donnÃ©es Supabase
NEXT_PUBLIC_SUPABASE_URL=http://localhost:54321
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Google Sheets (pour le mode production)
GOOGLE_SHEETS_ARTISANS_ID=your_sheet_id
GOOGLE_SHEETS_INTERVENTIONS_ID=your_sheet_id
GOOGLE_CREDENTIALS_PATH=./credentials.json
```

### **Options du script principal**

- `--local` : Mode dÃ©veloppement local
- `--dry-run` : Mode test sans Ã©criture
- `--verbose` : Affichage dÃ©taillÃ©
- `--artisans-only` : Import uniquement des artisans
- `--interventions-only` : Import uniquement des interventions
- `--batch-size=N` : Taille des lots d'insertion

## ğŸ¯ Avantages de cette architecture

1. **ModularitÃ©** : Chaque module a une responsabilitÃ© claire
2. **TestabilitÃ©** : Tests unitaires complets
3. **MaintenabilitÃ©** : Code organisÃ© et documentÃ©
4. **Ã‰volutivitÃ©** : Facile d'ajouter de nouveaux mappers
5. **Robustesse** : Gestion d'erreurs et validation
6. **RÃ©utilisabilitÃ©** : Utilise l'API existante
7. **FlexibilitÃ©** : Mode local et production

## ğŸš¨ Points d'attention

- **RÃ©fÃ©rences manquantes** : Les statuts, mÃ©tiers, agences doivent exister en base
- **DonnÃ©es dupliquÃ©es** : GÃ©rer les doublons potentiels
- **Performance** : Traitement par lots pour les gros volumes
- **Rollback** : PrÃ©voir un mÃ©canisme d'annulation en cas d'erreur

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifiez les logs dÃ©taillÃ©s avec `--verbose`
2. Consultez les fichiers de rÃ©sultats dans `./data/processed/`
3. Lancez les tests unitaires pour valider le mapping
4. VÃ©rifiez la configuration de la base de donnÃ©es